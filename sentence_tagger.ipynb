{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.callbacks import wandb_tracing_enabled\n",
    "\n",
    "\n",
    "os.environ[\"LANGCHAIN_WANDB_TRACING\"] = \"true\"\n",
    "os.environ[\"WANDB_PROJECT\"] = \"langchain-tracing\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "\n",
    "class Tags(BaseModel):\n",
    "    sentiment: str = Field(..., enum=[\"happy\", \"sad\", \"neutral\", \"angry\"])\n",
    "    aggressiveness: int = Field(...,\n",
    "        description=\"describes how aggressive the statement is, the higher the number the more aggressive\",\n",
    "        enum=[1, 2, 3, 4, 5],\n",
    "    )\n",
    "    tone: str = Field(..., \n",
    "        enum=[\"formal\", \"informal\", \"friendly\", \"assertive\", \"humorous\", \"sympathetic\", \"authoritative\", \"neutral\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts.chat import ChatPromptTemplate\n",
    "from langchain.chains.structured_output.base import create_structured_output_runnable\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(temperature=1)\n",
    "structured_llm = create_structured_output_runnable(\n",
    "    Tags,\n",
    "    llm,\n",
    "    mode=\"openai-tools\",\n",
    "    enforce_function_usage=True,\n",
    "    return_single=True\n",
    ")\n",
    "tagger_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"you are world class sentence tagger\"),\n",
    "        (\"human\", \"tag the given sentence:\\n\\n{sentence}\"),\n",
    "    ]\n",
    ")\n",
    "tagger_chain = (tagger_prompt | structured_llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "prompt2 = ChatPromptTemplate.from_messages([(\"human\", \"rephrase the sentence using this tag information:\\n\\ntag: {tag}\\n\\nsentence: {sentence}\")])\n",
    "\n",
    "chain2 = (\n",
    "    {\"tag\": tagger_chain, \"sentence\": itemgetter(\"sentence\")}\n",
    "    | prompt2\n",
    "    | llm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Streaming LangChain activity to W&B at https://wandb.ai/parth-singh71/langchain-tracing/runs/mlr5pmba\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: `WandbTracer` is currently in beta.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Please report any issues to https://github.com/wandb/wandb/issues with the tag `langchain`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"sentence\": \"And then a puppy came to his life and showed him what it means to love and be loved.\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableParallel<tag,sentence>] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"sentence\": \"And then a puppy came to his life and showed him what it means to love and be loved.\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableParallel<tag,sentence> > 3:chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"sentence\": \"And then a puppy came to his life and showed him what it means to love and be loved.\"\n",
      "}\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableParallel<tag,sentence> > 4:chain:RunnableLambda] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"sentence\": \"And then a puppy came to his life and showed him what it means to love and be loved.\"\n",
      "}\n",
      "\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableParallel<tag,sentence> > 3:chain:RunnableSequence > 4:prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m{\n",
      "  \"sentence\": \"And then a puppy came to his life and showed him what it means to love and be loved.\"\n",
      "}\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableParallel<tag,sentence> > 4:chain:RunnableLambda] [1ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"And then a puppy came to his life and showed him what it means to love and be loved.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableParallel<tag,sentence> > 3:chain:RunnableSequence > 4:prompt:ChatPromptTemplate] [1ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableParallel<tag,sentence> > 3:chain:RunnableSequence > 5:llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"System: you are world class sentence tagger\\nHuman: tag the given sentence:\\n\\nAnd then a puppy came to his life and showed him what it means to love and be loved.\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableParallel<tag,sentence> > 3:chain:RunnableSequence > 5:llm:ChatOpenAI] [1.08s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"\",\n",
      "            \"additional_kwargs\": {\n",
      "              \"tool_calls\": [\n",
      "                {\n",
      "                  \"id\": \"call_6WUHvvqFci1q1nxFQ1lycsmj\",\n",
      "                  \"function\": {\n",
      "                    \"arguments\": \"{\\\"sentiment\\\":\\\"happy\\\",\\\"aggressiveness\\\":1,\\\"tone\\\":\\\"sympathetic\\\"}\",\n",
      "                    \"name\": \"Tags\"\n",
      "                  },\n",
      "                  \"type\": \"function\"\n",
      "                }\n",
      "              ]\n",
      "            },\n",
      "            \"name\": null,\n",
      "            \"id\": null\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 19,\n",
      "      \"prompt_tokens\": 169,\n",
      "      \"total_tokens\": 188\n",
      "    },\n",
      "    \"model_name\": \"gpt-3.5-turbo\",\n",
      "    \"system_fingerprint\": \"fp_b28b39ffa8\"\n",
      "  },\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableParallel<tag,sentence> > 3:chain:RunnableSequence > 6:parser:PydanticToolsParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableParallel<tag,sentence> > 3:chain:RunnableSequence > 6:parser:PydanticToolsParser] [1ms] Exiting Parser run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableParallel<tag,sentence> > 3:chain:RunnableSequence] [1.09s] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableParallel<tag,sentence>] [1.09s] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 7:prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 7:prompt:ChatPromptTemplate] [1ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 8:llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: rephrase the sentence using this tag information:\\n\\ntag: sentiment='happy' aggressiveness=1 tone='sympathetic'\\n\\nsentence: And then a puppy came to his life and showed him what it means to love and be loved.\"\n",
      "  ]\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WARNING: Failed to serialize model: 'int' object is not subscriptable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 8:llm:ChatOpenAI] [1.44s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"The puppy entering his life brought him immense joy and taught him the true meaning of love and companionship. #happy #sympathetic\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"The puppy entering his life brought him immense joy and taught him the true meaning of love and companionship. #happy #sympathetic\",\n",
      "            \"additional_kwargs\": {},\n",
      "            \"name\": null,\n",
      "            \"id\": null\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 28,\n",
      "      \"prompt_tokens\": 55,\n",
      "      \"total_tokens\": 83\n",
      "    },\n",
      "    \"model_name\": \"gpt-3.5-turbo\",\n",
      "    \"system_fingerprint\": \"fp_3bc1b5746c\"\n",
      "  },\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence] [2.53s] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'content': 'The puppy entering his life brought him immense joy and taught him the true meaning of love and companionship. #happy #sympathetic',\n",
       " 'additional_kwargs': {},\n",
       " 'response_metadata': {'token_usage': {'completion_tokens': 28,\n",
       "   'prompt_tokens': 55,\n",
       "   'total_tokens': 83},\n",
       "  'model_name': 'gpt-3.5-turbo',\n",
       "  'system_fingerprint': 'fp_3bc1b5746c',\n",
       "  'finish_reason': 'stop',\n",
       "  'logprobs': None},\n",
       " 'type': 'ai',\n",
       " 'name': None,\n",
       " 'id': None,\n",
       " 'example': False}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.callbacks.tracers import ConsoleCallbackHandler\n",
    "\n",
    "\n",
    "# Now, we unset the environment variable and use a context manager.\n",
    "if \"LANGCHAIN_WANDB_TRACING\" in os.environ:\n",
    "    del os.environ[\"LANGCHAIN_WANDB_TRACING\"]\n",
    "\n",
    "# enable tracing using a context manager\n",
    "with wandb_tracing_enabled():\n",
    "    response = chain2.invoke({\n",
    "            \"sentence\": \"And then a puppy came to his life and showed him what it means to love and be loved.\",\n",
    "        }, \n",
    "        config={'callbacks': [ConsoleCallbackHandler()]}\n",
    "    )\n",
    "\n",
    "import json\n",
    "\n",
    "json.loads(response.json())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
